{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ChristopherHyland/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed \n",
    "seed(1) \n",
    "from tensorflow import set_random_seed \n",
    "set_random_seed(2)\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "#Stop warnings\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model I got was the best one I've found so from just playing around with the parameters. However, it is from far being an optimal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Wide Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model2():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model.add(Dense(input_dim=6, output_dim = 60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(10000, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1000, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(250, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model2():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model.add(Dense(input_dim=6, output_dim = 30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'linear'))\n",
    "    adam = optimizers.adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ATM_Training.csv')\n",
    "y = data.pop('Withdraw')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=42)\n",
    "X_train +=0.001\n",
    "X_test +=0.001\n",
    "scaler = StandardScaler()\n",
    "X_tran = scaler.fit(X_train.iloc[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = X_tran.transform(X_train.iloc[:,0:2])\n",
    "dat2 = X_tran.transform(X_test.iloc[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.pop('Shops')\n",
    "X_train.pop('ATMs')\n",
    "X_test.pop('Shops')\n",
    "X_test.pop('ATMs')\n",
    "X_train += 0.01\n",
    "X_test += 0.01\n",
    "data1train = []\n",
    "data2train = []\n",
    "data1test = []\n",
    "data2test = []\n",
    "for i in range(len(dat)):\n",
    "    data1train.append(dat[i][0])\n",
    "    data2train.append(dat[i][1])\n",
    "for i in range(len(dat2)):\n",
    "    data1test.append(dat2[i][0])\n",
    "    data2test.append(dat2[i][1])\n",
    "    \n",
    "X_train['Shops'] = data1train\n",
    "X_train['ATM'] = data2train\n",
    "X_test['Shops'] = data1test\n",
    "X_test['ATM'] = data2test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def baseline_model4():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model.add(Dense(input_dim=6, output_dim = 250, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(1000, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(250, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14740/14740 [==============================] - 5s - loss: 230.2685     \n",
      "Epoch 2/25\n",
      "14740/14740 [==============================] - 5s - loss: 1.5270     \n",
      "Epoch 3/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.4776     \n",
      "Epoch 4/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3841     \n",
      "Epoch 5/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3378     \n",
      "Epoch 6/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3259     \n",
      "Epoch 7/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3525     \n",
      "Epoch 8/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3310     \n",
      "Epoch 9/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3608     \n",
      "Epoch 10/25\n",
      "14740/14740 [==============================] - 7s - loss: 0.3307     \n",
      "Epoch 11/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3857     \n",
      "Epoch 12/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3628     \n",
      "Epoch 13/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3512     \n",
      "Epoch 14/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3576     \n",
      "Epoch 15/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.4593     \n",
      "Epoch 16/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.4613     \n",
      "Epoch 17/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.4034     \n",
      "Epoch 18/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.4129     \n",
      "Epoch 19/25\n",
      "14740/14740 [==============================] - 6s - loss: 0.4779     \n",
      "Epoch 20/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.4379     \n",
      "Epoch 21/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.4142     \n",
      "Epoch 22/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3781     \n",
      "Epoch 23/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.4773     \n",
      "Epoch 24/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3675     \n",
      "Epoch 25/25\n",
      "14740/14740 [==============================] - 6s - loss: 0.4894     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1382e6b70>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = baseline_model4()\n",
    "model3.fit(X_train.as_matrix(), y_train, nb_epoch=25, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7008/7260 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "MSE_nn = model3.evaluate(X_test.as_matrix(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE is 0.3419023290974378\n"
     ]
    }
   ],
   "source": [
    "print('Final MSE is {mse}'.format(mse = MSE_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. Dense (init = Gaussian) -> Gaussian Noise(0.05->0.1) -> \n",
    "#PRELU or Leaky-RELU(0.1->0.3) -> BatchNormalisation -> Gaussian Dropout (0.1->0.3) -> 2. Dense and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#= NAdam (lr = 0.005, momentum = 0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NAdam optimiser (nesterov Adam)\n",
    "#Batch Norm\n",
    "#PRELU\n",
    "#Gaussian Noise/Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model2():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model.add(Dense(input_dim=6, output_dim = 30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "    \n",
    "  \n",
    "model2 = baseline_model2()\n",
    "model2.fit(X_train.as_matrix(), y_train, nb_epoch=25, batch_size=50)\n",
    "MSE_nn = model2.evaluate(X_test.as_matrix(), y_test)\n",
    "print('Final MSE is {mse}'.format(mse = MSE_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.2642245148660066"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
