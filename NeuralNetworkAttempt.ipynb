{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#Stop warnings\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ATM_Training.csv')\n",
    "y = data.pop('Withdraw')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    \"\"\"Baseline neural network model by playing around with parameters.\"\"\"\n",
    "    #Construct a neural network object:\n",
    "    model = Sequential()\n",
    "    #Input dimension for input layer MUST match the number of predictors in our dataset. Output dimension tells us \n",
    "    #how many edges going into next layer (can be any number from 1 to number of vertices in next layer). \n",
    "    #Kernel_init tells us what initial weightings to set the weights when training it. Relu is activation function:\n",
    "    model.add(Dense(input_dim=6, output_dim = 60, kernel_initializer='normal', activation='relu'))\n",
    "    #Here we created a layer with 60 vertices and the same parameters as before:\n",
    "    model.add(Dense(60, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(60, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(15, kernel_initializer='normal', activation = 'relu'))    \n",
    "    model.add(Dense(6, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'relu'))\n",
    "    # Compile model from this. Keep this loss function whilst ADAM is a better optimizer than SGD:\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Need to transform from pandas df into matrix for keras to work with. Then since alot of the predictors are dummy\n",
    "#variables, this means that when training and learning, the model won't update since alot of 0's in our data.\n",
    "#Therefore, add a small number to ensure we update the parameters.\n",
    "xarray = X_train.as_matrix()\n",
    "xarray = xarray+0.0001\n",
    "xarrayTest = X_test+0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14740/14740 [==============================] - 3s - loss: 932.6389     \n",
      "Epoch 2/25\n",
      "14740/14740 [==============================] - 1s - loss: 27.3211     \n",
      "Epoch 3/25\n",
      "14740/14740 [==============================] - 2s - loss: 10.1579     \n",
      "Epoch 4/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.6642     \n",
      "Epoch 5/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.2171     \n",
      "Epoch 6/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.2654     \n",
      "Epoch 7/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.0758     \n",
      "Epoch 8/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.1935     \n",
      "Epoch 9/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.3290     \n",
      "Epoch 10/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1299     \n",
      "Epoch 11/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.1809     \n",
      "Epoch 12/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1763     \n",
      "Epoch 13/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.5119     \n",
      "Epoch 14/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1438     \n",
      "Epoch 15/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1664     \n",
      "Epoch 16/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.5256     \n",
      "Epoch 17/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1287     \n",
      "Epoch 18/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.2381     \n",
      "Epoch 19/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.0771     \n",
      "Epoch 20/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.0649     \n",
      "Epoch 21/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.1505     \n",
      "Epoch 22/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1263     \n",
      "Epoch 23/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.0391     \n",
      "Epoch 24/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.4256     \n",
      "Epoch 25/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.0433     \n",
      "Final MSE is  6.25379051441\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(xarray, y_train, nb_epoch=25, batch_size=50)\n",
    "predictions = model.predict(X_test.as_matrix())\n",
    "test = list(predictions)\n",
    "print('Final MSE is ',mean_squared_error(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model I got was the best one I've found so from just playing around with the parameters. However, it is from far being an optimal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Wide Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('ATM_Training.csv')\n",
    "y = data.pop('Withdraw')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=42)\n",
    "X_train +=0.01\n",
    "X_test +=0.01\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_Train = scaler.transform(X_train)\n",
    "X_Test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model2():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=6, output_dim = 60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1000, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(250, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14740/14740 [==============================] - 3s - loss: 313.7435     \n",
      "Epoch 2/25\n",
      "14740/14740 [==============================] - 2s - loss: 1.0115     \n",
      "Epoch 3/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.7454     \n",
      "Epoch 4/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.5708     \n",
      "Epoch 5/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.4503     \n",
      "Epoch 6/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3795     \n",
      "Epoch 7/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.3619     \n",
      "Epoch 8/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3505     \n",
      "Epoch 9/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.3581     \n",
      "Epoch 10/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.3563     \n",
      "Epoch 11/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3785     \n",
      "Epoch 12/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.3556     \n",
      "Epoch 13/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3697     \n",
      "Epoch 14/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.4603     \n",
      "Epoch 15/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3626     \n",
      "Epoch 16/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4034     \n",
      "Epoch 17/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3723     \n",
      "Epoch 18/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4781     \n",
      "Epoch 19/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.4180     \n",
      "Epoch 20/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.4133     \n",
      "Epoch 21/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4228     \n",
      "Epoch 22/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4569     \n",
      "Epoch 23/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3837     \n",
      "Epoch 24/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.4288     - ETA: 0s - loss: 0.\n",
      "Epoch 25/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3923     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1306be3c8>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model2()\n",
    "model.fit(X_Train, y_train, nb_epoch=25, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7168/7260 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "MSE_nn = model.evaluate(X_Test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE is 0.27606850176146536\n"
     ]
    }
   ],
   "source": [
    "print('Final MSE is {mse}'.format(mse = MSE_nn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
