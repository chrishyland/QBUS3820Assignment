{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed \n",
    "seed(1) \n",
    "from tensorflow import set_random_seed \n",
    "set_random_seed(2)\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "#Stop warnings\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model I got was the best one I've found so from just playing around with the parameters. However, it is from far being an optimal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Wide Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=6, output_dim = 24, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(24, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(12, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model2():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model.add(Dense(input_dim=6, output_dim = 60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(10000, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1000, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(250, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model3():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model.add(Dense(input_dim=6, output_dim = 30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(30, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(30, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(30, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'linear'))\n",
    "#    adam = optimizers.adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ATM_Training.csv')\n",
    "y = data.pop('Withdraw')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=42)\n",
    "X_train +=0.001\n",
    "X_test +=0.001\n",
    "scaler = StandardScaler()\n",
    "X_tran = scaler.fit(X_train.iloc[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = X_tran.transform(X_train.iloc[:,0:2])\n",
    "dat2 = X_tran.transform(X_test.iloc[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.pop('Shops')\n",
    "X_train.pop('ATMs')\n",
    "X_test.pop('Shops')\n",
    "X_test.pop('ATMs')\n",
    "X_train += 0.01\n",
    "X_test += 0.01\n",
    "data1train = []\n",
    "data2train = []\n",
    "data1test = []\n",
    "data2test = []\n",
    "for i in range(len(dat)):\n",
    "    data1train.append(dat[i][0])\n",
    "    data2train.append(dat[i][1])\n",
    "for i in range(len(dat2)):\n",
    "    data1test.append(dat2[i][0])\n",
    "    data2test.append(dat2[i][1])\n",
    "    \n",
    "X_train['Shops'] = data1train\n",
    "X_train['ATM'] = data2train\n",
    "X_test['Shops'] = data1test\n",
    "X_test['ATM'] = data2test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def baseline_model4():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model.add(Dense(input_dim=6, output_dim = 250, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(1000, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(250, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "14740/14740 [==============================] - 2s - loss: 1859.9109     \n",
      "Epoch 2/40\n",
      "14740/14740 [==============================] - 1s - loss: 82.1370     \n",
      "Epoch 3/40\n",
      "14740/14740 [==============================] - 2s - loss: 23.1209     \n",
      "Epoch 4/40\n",
      "14740/14740 [==============================] - 1s - loss: 8.2837     \n",
      "Epoch 5/40\n",
      "14740/14740 [==============================] - 2s - loss: 6.7781     \n",
      "Epoch 6/40\n",
      "14740/14740 [==============================] - 2s - loss: 6.6946     \n",
      "Epoch 7/40\n",
      "14740/14740 [==============================] - 1s - loss: 6.5936     \n",
      "Epoch 8/40\n",
      "14740/14740 [==============================] - 1s - loss: 6.5207     \n",
      "Epoch 9/40\n",
      "14740/14740 [==============================] - 1s - loss: 6.4638     \n",
      "Epoch 10/40\n",
      "14740/14740 [==============================] - 1s - loss: 6.4081     \n",
      "Epoch 11/40\n",
      "14740/14740 [==============================] - 1s - loss: 6.3819     \n",
      "Epoch 12/40\n",
      "14740/14740 [==============================] - 2s - loss: 6.3480     \n",
      "Epoch 13/40\n",
      "14740/14740 [==============================] - 1s - loss: 6.2943     \n",
      "Epoch 14/40\n",
      "14740/14740 [==============================] - 1s - loss: 6.2663     \n",
      "Epoch 15/40\n",
      "14740/14740 [==============================] - 1s - loss: 6.1712     \n",
      "Epoch 16/40\n",
      "14740/14740 [==============================] - 1s - loss: 5.9537     \n",
      "Epoch 17/40\n",
      "14740/14740 [==============================] - 1s - loss: 5.5971     \n",
      "Epoch 18/40\n",
      "14740/14740 [==============================] - 1s - loss: 5.0514     \n",
      "Epoch 19/40\n",
      "14740/14740 [==============================] - 1s - loss: 4.4934     \n",
      "Epoch 20/40\n",
      "14740/14740 [==============================] - 2s - loss: 3.6204     \n",
      "Epoch 21/40\n",
      "14740/14740 [==============================] - 1s - loss: 2.6328     \n",
      "Epoch 22/40\n",
      "14740/14740 [==============================] - 1s - loss: 1.5656     \n",
      "Epoch 23/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.8656     \n",
      "Epoch 24/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.5446     \n",
      "Epoch 25/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.3986     \n",
      "Epoch 26/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.3450     \n",
      "Epoch 27/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.3129     \n",
      "Epoch 28/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.3036     \n",
      "Epoch 29/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.2846     \n",
      "Epoch 30/40\n",
      "14740/14740 [==============================] - 2s - loss: 0.2749     \n",
      "Epoch 31/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.2682     \n",
      "Epoch 32/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.2700     \n",
      "Epoch 33/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.2765     \n",
      "Epoch 34/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.2627     \n",
      "Epoch 35/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.2723     \n",
      "Epoch 36/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.2722     \n",
      "Epoch 37/40\n",
      "14740/14740 [==============================] - 2s - loss: 0.2660     \n",
      "Epoch 38/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.2655     \n",
      "Epoch 39/40\n",
      "14740/14740 [==============================] - 2s - loss: 0.2656     \n",
      "Epoch 40/40\n",
      "14740/14740 [==============================] - 1s - loss: 0.2704     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1508a1f28>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = baseline_model()\n",
    "model3.fit(X_train.as_matrix(), y_train, nb_epoch=40, batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7168/7260 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "MSE_nn = model3.evaluate(X_test.as_matrix(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE is 0.25218316820698994\n"
     ]
    }
   ],
   "source": [
    "print('Final MSE is {mse}'.format(mse = MSE_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. Dense (init = Gaussian) -> Gaussian Noise(0.05->0.1) -> \n",
    "#PRELU or Leaky-RELU(0.1->0.3) -> BatchNormalisation -> Gaussian Dropout (0.1->0.3) -> 2. Dense and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#= NAdam (lr = 0.005, momentum = 0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NAdam optimiser (nesterov Adam)\n",
    "#Batch Norm\n",
    "#PRELU\n",
    "#Gaussian Noise/Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=6, output_dim = 24, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(24, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(12, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model3 = baseline_model()\n",
    "model3.fit(X_train.as_matrix(), y_train, nb_epoch=40, batch_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.2525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
