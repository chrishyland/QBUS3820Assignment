{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337) # for reproducibility\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Stop warnings\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ATM_Training.csv')\n",
    "y = data.pop('Withdraw')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    \"\"\"Baseline neural network model by playing around with parameters.\"\"\"\n",
    "    #Construct a neural network object:\n",
    "    model = Sequential()\n",
    "    #Input dimension for input layer MUST match the number of predictors in our dataset. Output dimension tells us \n",
    "    #how many edges going into next layer (can be any number from 1 to number of vertices in next layer). \n",
    "    #Kernel_init tells us what initial weightings to set the weights when training it. Relu is activation function:\n",
    "    model.add(Dense(input_dim=6, output_dim = 60, kernel_initializer='normal', activation='relu'))\n",
    "    #Here we created a layer with 60 vertices and the same parameters as before:\n",
    "    model.add(Dense(60, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(60, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(15, kernel_initializer='normal', activation = 'relu'))    \n",
    "    model.add(Dense(6, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'relu'))\n",
    "    # Compile model from this. Keep this loss function whilst ADAM is a better optimizer than SGD:\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Need to transform from pandas df into matrix for keras to work with. Then since alot of the predictors are dummy\n",
    "#variables, this means that when training and learning, the model won't update since alot of 0's in our data.\n",
    "#Therefore, add a small number to ensure we update the parameters.\n",
    "xarray = X_train.as_matrix()\n",
    "xarray = xarray+0.0001\n",
    "xarrayTest = X_test+0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14740/14740 [==============================] - 3s - loss: 932.6389     \n",
      "Epoch 2/25\n",
      "14740/14740 [==============================] - 1s - loss: 27.3211     \n",
      "Epoch 3/25\n",
      "14740/14740 [==============================] - 2s - loss: 10.1579     \n",
      "Epoch 4/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.6642     \n",
      "Epoch 5/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.2171     \n",
      "Epoch 6/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.2654     \n",
      "Epoch 7/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.0758     \n",
      "Epoch 8/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.1935     \n",
      "Epoch 9/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.3290     \n",
      "Epoch 10/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1299     \n",
      "Epoch 11/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.1809     \n",
      "Epoch 12/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1763     \n",
      "Epoch 13/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.5119     \n",
      "Epoch 14/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1438     \n",
      "Epoch 15/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1664     \n",
      "Epoch 16/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.5256     \n",
      "Epoch 17/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1287     \n",
      "Epoch 18/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.2381     \n",
      "Epoch 19/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.0771     \n",
      "Epoch 20/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.0649     \n",
      "Epoch 21/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.1505     \n",
      "Epoch 22/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.1263     \n",
      "Epoch 23/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.0391     \n",
      "Epoch 24/25\n",
      "14740/14740 [==============================] - 2s - loss: 7.4256     \n",
      "Epoch 25/25\n",
      "14740/14740 [==============================] - 1s - loss: 7.0433     \n",
      "Final MSE is  6.25379051441\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(xarray, y_train, nb_epoch=25, batch_size=50)\n",
    "predictions = model.predict(X_test.as_matrix())\n",
    "test = list(predictions)\n",
    "print('Final MSE is ',mean_squared_error(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network model I got was the best one I've found so from just playing around with the parameters. However, it is from far being an optimal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Wide Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model2():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model.add(Dense(input_dim=6, output_dim = 60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1000, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(250, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model3():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=6, output_dim = 60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1000, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(250, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'relu'))\n",
    "    ada = optimizers.Adam(decay=0)\n",
    "    model.compile(loss='mean_squared_error', optimizer=ada)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14740/14740 [==============================] - 4s - loss: 301.4487     \n",
      "Epoch 2/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.8125     \n",
      "Epoch 3/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.6255     \n",
      "Epoch 4/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.5129     \n",
      "Epoch 5/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4396     \n",
      "Epoch 6/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3849     \n",
      "Epoch 7/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3966     \n",
      "Epoch 8/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3608     \n",
      "Epoch 9/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3753     \n",
      "Epoch 10/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3436     \n",
      "Epoch 11/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4037     \n",
      "Epoch 12/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3819     \n",
      "Epoch 13/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3632     \n",
      "Epoch 14/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3833     \n",
      "Epoch 15/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4083     \n",
      "Epoch 16/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3876     \n",
      "Epoch 17/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.5425     \n",
      "Epoch 18/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.4246     \n",
      "Epoch 19/25\n",
      " 3200/14740 [=====>........................] - ETA: 1s - loss: 0.4835"
     ]
    }
   ],
   "source": [
    "model6 = baseline_model3()\n",
    "model6.fit(X_Train, y_train, nb_epoch=25, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7260 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "MSE_nn = model6.evaluate(X_Test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE is 0.35583991556128197\n"
     ]
    }
   ],
   "source": [
    "print('Final MSE is {mse}'.format(mse = MSE_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14740/14740 [==============================] - 2s - loss: 465.0814     \n",
      "Epoch 2/30\n",
      "14740/14740 [==============================] - 2s - loss: 1.5581     \n",
      "Epoch 3/30\n",
      "14740/14740 [==============================] - 1s - loss: 0.9577     \n",
      "Epoch 4/30\n",
      "14740/14740 [==============================] - 3s - loss: 0.7789     \n",
      "Epoch 5/30\n",
      "14740/14740 [==============================] - 1s - loss: 0.6473     \n",
      "Epoch 6/30\n",
      "14740/14740 [==============================] - 3s - loss: 0.5354     \n",
      "Epoch 7/30\n",
      "14740/14740 [==============================] - 1s - loss: 0.4701     \n",
      "Epoch 8/30\n",
      "14740/14740 [==============================] - 3s - loss: 0.3956     \n",
      "Epoch 9/30\n",
      "14740/14740 [==============================] - 2s - loss: 0.3799     \n",
      "Epoch 10/30\n",
      "14740/14740 [==============================] - 3s - loss: 0.3379     \n",
      "Epoch 11/30\n",
      "14740/14740 [==============================] - 1s - loss: 0.3340     \n",
      "Epoch 12/30\n",
      "14740/14740 [==============================] - 3s - loss: 0.3317     \n",
      "Epoch 13/30\n",
      "14740/14740 [==============================] - 2s - loss: 0.3180     \n",
      "Epoch 14/30\n",
      "14740/14740 [==============================] - 3s - loss: 0.3166     \n",
      "Epoch 15/30\n",
      "14740/14740 [==============================] - 2s - loss: 0.3196     \n",
      "Epoch 16/30\n",
      "14740/14740 [==============================] - 2s - loss: 0.3401     \n",
      "Epoch 17/30\n",
      "14740/14740 [==============================] - 2s - loss: 0.3376     \n",
      "Epoch 18/30\n",
      "14740/14740 [==============================] - 2s - loss: 0.3584     \n",
      "Epoch 19/30\n",
      "14740/14740 [==============================] - 3s - loss: 0.3539     \n",
      "Epoch 20/30\n",
      "14740/14740 [==============================] - 1s - loss: 0.3410     \n",
      "Epoch 21/30\n",
      "14740/14740 [==============================] - 3s - loss: 0.3422     \n",
      "Epoch 22/30\n",
      "   75/14740 [..............................] - ETA: 4s - loss: 0.2446"
     ]
    }
   ],
   "source": [
    "model2 = baseline_model2()\n",
    "model2.fit(X_Train, y_train, nb_epoch=30, batch_size=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_nn = model.evaluate(X_Test, y_test)\n",
    "print('Final MSE is {mse}'.format(mse = MSE_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Neural network zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ATM_Training.csv')\n",
    "y = data.pop('Withdraw')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, random_state=42)\n",
    "#X_train +=0.01\n",
    "#X_test +=0.01\n",
    "scaler = StandardScaler()\n",
    "X_tran = scaler.fit(X_train.iloc[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = X_tran.transform(X_train.iloc[:,0:2])\n",
    "dat2 = X_tran.transform(X_test.iloc[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.pop('Shops')\n",
    "X_train.pop('ATMs')\n",
    "X_test.pop('Shops')\n",
    "X_test.pop('ATMs')\n",
    "X_train += 0.01\n",
    "X_test += 0.01\n",
    "data1train = []\n",
    "data2train = []\n",
    "data1test = []\n",
    "data2test = []\n",
    "for i in range(len(dat)):\n",
    "    data1train.append(dat[i][0])\n",
    "    data2train.append(dat[i][1])\n",
    "for i in range(len(dat2)):\n",
    "    data1test.append(dat2[i][0])\n",
    "    data2test.append(dat2[i][1])\n",
    "    \n",
    "X_train['Shops'] = data1train\n",
    "X_train['ATM'] = data2train\n",
    "X_test['Shops'] = data1test\n",
    "X_test['ATM'] = data2test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14740/14740 [==============================] - 4s - loss: 337.6114     \n",
      "Epoch 2/25\n",
      "14740/14740 [==============================] - 3s - loss: 3.1279     \n",
      "Epoch 3/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.7491     \n",
      "Epoch 4/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.5043     \n",
      "Epoch 5/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3858     \n",
      "Epoch 6/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3377     \n",
      "Epoch 7/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3161     \n",
      "Epoch 8/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3074     \n",
      "Epoch 9/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3119     \n",
      "Epoch 10/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.2884     \n",
      "Epoch 11/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3420     \n",
      "Epoch 12/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3082     \n",
      "Epoch 13/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3073     \n",
      "Epoch 14/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3091     \n",
      "Epoch 15/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3532     \n",
      "Epoch 16/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3591     - ETA: 0s - los\n",
      "Epoch 17/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.3688     \n",
      "Epoch 18/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3587     \n",
      "Epoch 19/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4170     \n",
      "Epoch 20/25\n",
      "14740/14740 [==============================] - 5s - loss: 0.3487     \n",
      "Epoch 21/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3505     \n",
      "Epoch 22/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3215     \n",
      "Epoch 23/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.3856     \n",
      "Epoch 24/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3355     \n",
      "Epoch 25/25\n",
      "14740/14740 [==============================] - ETA: 0s - loss: 0.346 - 2s - loss: 0.3461     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e96be80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model2()\n",
    "model.fit(X_train.as_matrix(), y_train, nb_epoch=25, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7168/7260 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "MSE_nn = model.evaluate(X_test.as_matrix(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE is 0.3869362514373685\n"
     ]
    }
   ],
   "source": [
    "print('Final MSE is {mse}'.format(mse = MSE_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model3():\n",
    "    \"\"\"Wide neural network model.\"\"\"\n",
    "    model = Sequential()\n",
    "    np.random.seed(1337) # for reproducibility\n",
    "    model.add(Dense(input_dim=6, output_dim = 60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(60, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1000, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(250, kernel_initializer='normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation = 'linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14740/14740 [==============================] - 4s - loss: 318.5412     \n",
      "Epoch 2/25\n",
      "14740/14740 [==============================] - 4s - loss: 1.1016     \n",
      "Epoch 3/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.6134     \n",
      "Epoch 4/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4369     \n",
      "Epoch 5/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3347     \n",
      "Epoch 6/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3144     \n",
      "Epoch 7/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3176     \n",
      "Epoch 8/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.3416     \n",
      "Epoch 9/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3092     \n",
      "Epoch 10/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3444     \n",
      "Epoch 11/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3353     - ETA: 0s -  - ETA: 0s - loss: \n",
      "Epoch 12/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3589     \n",
      "Epoch 13/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3452     \n",
      "Epoch 14/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3700     \n",
      "Epoch 15/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.4059     \n",
      "Epoch 16/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.4048     \n",
      "Epoch 17/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3409     \n",
      "Epoch 18/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4657     \n",
      "Epoch 19/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.3880     - E\n",
      "Epoch 20/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.4118     \n",
      "Epoch 21/25\n",
      "14740/14740 [==============================] - 4s - loss: 0.4347     \n",
      "Epoch 22/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3528     \n",
      "Epoch 23/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3936     \n",
      "Epoch 24/25\n",
      "14740/14740 [==============================] - 2s - loss: 0.4093     \n",
      "Epoch 25/25\n",
      "14740/14740 [==============================] - 3s - loss: 0.3666     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1212602b0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = baseline_model3()\n",
    "model2.fit(X_train.as_matrix(), y_train, nb_epoch=25, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7072/7260 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "MSE_nn = model2.evaluate(X_test.as_matrix(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE is 0.3080970493394153\n"
     ]
    }
   ],
   "source": [
    "print('Final MSE is {mse}'.format(mse = MSE_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
